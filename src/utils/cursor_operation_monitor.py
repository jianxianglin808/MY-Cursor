#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Cursoræ“ä½œç›‘æ§å™¨ - ç›‘æ§å…¶ä»–æ¢å·è½¯ä»¶çš„æ“ä½œé€»è¾‘
ç”¨äºå­¦ä¹ å’Œåˆ†ææˆåŠŸçš„è´¦å·åˆ‡æ¢å®ç°
"""

import sqlite3
import json
import os
import time
import hashlib
import shutil
import threading
import logging
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler


class CursorDatabaseMonitor:
    """SQLiteæ•°æ®åº“å˜åŒ–ç›‘æ§å™¨"""
    
    def __init__(self, db_path: str, logger=None):
        self.db_path = db_path
        self.logger = logger or logging.getLogger(__name__)
        self.initial_state = {}
        self.monitoring = False
        self.changes_log = []
        
    def capture_initial_state(self) -> bool:
        """æ•è·æ•°æ®åº“åˆå§‹çŠ¶æ€"""
        try:
            if not os.path.exists(self.db_path):
                self.logger.error(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
                return False
                
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰ItemTableæ•°æ®
            cursor.execute("SELECT key, value FROM ItemTable")
            rows = cursor.fetchall()
            
            self.initial_state = {key: value for key, value in rows}
            conn.close()
            
            self.logger.info(f"âœ… å·²æ•è·æ•°æ®åº“åˆå§‹çŠ¶æ€: {len(self.initial_state)} ä¸ªé”®å€¼å¯¹")
            return True
            
        except Exception as e:
            self.logger.error(f"æ•è·åˆå§‹çŠ¶æ€å¤±è´¥: {str(e)}")
            return False
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§æ•°æ®åº“å˜åŒ–"""
        self.monitoring = True
        self.changes_log = []
        
        def monitor_loop():
            self.logger.info("ğŸ” å¼€å§‹ç›‘æ§æ•°æ®åº“å˜åŒ–...")
            
            while self.monitoring:
                try:
                    current_changes = self.detect_changes()
                    if current_changes:
                        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
                        self.changes_log.append({
                            'timestamp': timestamp,
                            'changes': current_changes
                        })
                        
                        self.logger.info(f"ğŸ“Š [{timestamp}] æ£€æµ‹åˆ° {len(current_changes)} ä¸ªå˜åŒ–:")
                        for change in current_changes:
                            self.logger.info(f"  {change['type']}: {change['key']} = {change['new_value'][:50] if change.get('new_value') else 'None'}...")
                    
                    time.sleep(0.5)  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
                    
                except Exception as e:
                    self.logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {str(e)}")
                    time.sleep(1)
        
        monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        self.logger.info("ğŸ›‘ æ•°æ®åº“ç›‘æ§å·²åœæ­¢")
    
    def detect_changes(self) -> List[Dict]:
        """æ£€æµ‹æ•°æ®åº“å˜åŒ–"""
        try:
            if not os.path.exists(self.db_path):
                return []
                
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT key, value FROM ItemTable")
            rows = cursor.fetchall()
            current_state = {key: value for key, value in rows}
            conn.close()
            
            changes = []
            
            # æ£€æµ‹æ–°å¢å’Œä¿®æ”¹
            for key, value in current_state.items():
                if key not in self.initial_state:
                    changes.append({
                        'type': 'ADDED',
                        'key': key,
                        'new_value': value,
                        'old_value': None
                    })
                elif self.initial_state[key] != value:
                    changes.append({
                        'type': 'MODIFIED',
                        'key': key,
                        'new_value': value,
                        'old_value': self.initial_state[key]
                    })
            
            # æ£€æµ‹åˆ é™¤
            for key in self.initial_state:
                if key not in current_state:
                    changes.append({
                        'type': 'DELETED',
                        'key': key,
                        'new_value': None,
                        'old_value': self.initial_state[key]
                    })
            
            # æ›´æ–°åˆå§‹çŠ¶æ€ä¸ºå½“å‰çŠ¶æ€
            self.initial_state = current_state
            
            return changes
            
        except Exception as e:
            self.logger.error(f"æ£€æµ‹å˜åŒ–å¤±è´¥: {str(e)}")
            return []
    
    def get_changes_summary(self) -> Dict:
        """è·å–å˜åŒ–æ€»ç»“"""
        if not self.changes_log:
            return {"total_changes": 0, "summary": "æ— å˜åŒ–"}
        
        total_changes = sum(len(log['changes']) for log in self.changes_log)
        
        # æŒ‰é”®åˆ†ç±»ç»Ÿè®¡
        key_stats = {}
        for log in self.changes_log:
            for change in log['changes']:
                key = change['key']
                change_type = change['type']
                
                if key not in key_stats:
                    key_stats[key] = {'ADDED': 0, 'MODIFIED': 0, 'DELETED': 0}
                key_stats[key][change_type] += 1
        
        return {
            "total_changes": total_changes,
            "total_logs": len(self.changes_log),
            "key_statistics": key_stats,
            "timeline": self.changes_log
        }


class CursorFileMonitor(FileSystemEventHandler):
    """Cursoré…ç½®æ–‡ä»¶ç›‘æ§å™¨"""
    
    def __init__(self, logger=None):
        self.logger = logger or logging.getLogger(__name__)
        self.changes_log = []
        
    def on_modified(self, event):
        if event.is_directory:
            return
            
        file_path = event.src_path
        filename = os.path.basename(file_path)
        
        # åªç›‘æ§å…³é”®æ–‡ä»¶
        if filename in ['storage.json', 'machineId', 'state.vscdb']:
            timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
            self.changes_log.append({
                'timestamp': timestamp,
                'type': 'MODIFIED',
                'file': file_path,
                'filename': filename
            })
            
            self.logger.info(f"ğŸ“ [{timestamp}] æ–‡ä»¶ä¿®æ”¹: {filename}")
            
            # å¦‚æœæ˜¯JSONæ–‡ä»¶ï¼Œå°è¯•è¯»å–å†…å®¹
            if filename == 'storage.json':
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = json.load(f)
                    
                    # è®°å½•æœºå™¨ç ç›¸å…³å­—æ®µ
                    machine_fields = {k: v for k, v in content.items() if 'machine' in k.lower() or 'telemetry' in k.lower()}
                    if machine_fields:
                        self.logger.info(f"  æœºå™¨ç å­—æ®µ: {list(machine_fields.keys())}")
                        
                except Exception as e:
                    self.logger.warning(f"è¯»å– {filename} å¤±è´¥: {str(e)}")
    
    def on_created(self, event):
        if event.is_directory:
            return
            
        file_path = event.src_path
        filename = os.path.basename(file_path)
        
        if filename in ['storage.json', 'machineId', 'state.vscdb']:
            timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
            self.changes_log.append({
                'timestamp': timestamp,
                'type': 'CREATED',
                'file': file_path,
                'filename': filename
            })
            
            self.logger.info(f"ğŸ“ [{timestamp}] æ–‡ä»¶åˆ›å»º: {filename}")
    
    def on_deleted(self, event):
        if event.is_directory:
            return
            
        file_path = event.src_path
        filename = os.path.basename(file_path)
        
        if filename in ['storage.json', 'machineId', 'state.vscdb']:
            timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
            self.changes_log.append({
                'timestamp': timestamp,
                'type': 'DELETED',
                'file': file_path,
                'filename': filename
            })
            
            self.logger.info(f"ğŸ“ [{timestamp}] æ–‡ä»¶åˆ é™¤: {filename}")


class CursorOperationMonitor:
    """Cursoræ“ä½œç»¼åˆç›‘æ§å™¨"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.db_path = config.get('cursor', 'db_path')
        
        # è·å–Cursorç”¨æˆ·æ•°æ®è·¯å¾„ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼‰
        cursor_data_dir = config.get_cursor_data_dir()
        self.user_data_path = os.path.join(cursor_data_dir, "User")
        
        self.db_monitor = CursorDatabaseMonitor(self.db_path, self.logger)
        self.file_monitor = CursorFileMonitor(self.logger)
        self.observer = None
        
    def start_comprehensive_monitoring(self) -> bool:
        """å¼€å§‹ç»¼åˆç›‘æ§"""
        try:
            self.logger.info("ğŸš€ å¯åŠ¨Cursoræ“ä½œç»¼åˆç›‘æ§...")
            
            # 1. æ•è·æ•°æ®åº“åˆå§‹çŠ¶æ€
            if not self.db_monitor.capture_initial_state():
                return False
            
            # 2. å¯åŠ¨æ•°æ®åº“ç›‘æ§
            self.db_monitor.start_monitoring()
            
            # 3. å¯åŠ¨æ–‡ä»¶ç³»ç»Ÿç›‘æ§
            self.observer = Observer()
            
            # ç›‘æ§å…³é”®ç›®å½•
            monitor_paths = [
                os.path.dirname(self.db_path),  # globalStorageç›®å½•
                os.path.join(os.getenv("APPDATA", ""), "Cursor"),  # Cursoræ ¹ç›®å½•
            ]
            
            for path in monitor_paths:
                if os.path.exists(path):
                    self.observer.schedule(self.file_monitor, path, recursive=True)
                    self.logger.info(f"ğŸ“‚ ç›‘æ§ç›®å½•: {path}")
            
            self.observer.start()
            
            self.logger.info("âœ… ç»¼åˆç›‘æ§å·²å¯åŠ¨ï¼Œè¯·åœ¨å¦ä¸€ä¸ªè½¯ä»¶ä¸­æ‰§è¡Œè´¦å·åˆ‡æ¢æ“ä½œ")
            self.logger.info("ğŸ“ ç›‘æ§å°†è®°å½•æ‰€æœ‰æ•°æ®åº“å’Œæ–‡ä»¶å˜åŒ–")
            
            return True
            
        except Exception as e:
            self.logger.error(f"å¯åŠ¨ç›‘æ§å¤±è´¥: {str(e)}")
            return False
    
    def stop_monitoring(self) -> Dict:
        """åœæ­¢ç›‘æ§å¹¶è¿”å›ç»“æœ"""
        try:
            self.logger.info("ğŸ›‘ åœæ­¢ç›‘æ§...")
            
            # åœæ­¢æ•°æ®åº“ç›‘æ§
            self.db_monitor.stop_monitoring()
            
            # åœæ­¢æ–‡ä»¶ç›‘æ§
            if self.observer:
                self.observer.stop()
                self.observer.join()
            
            # æ”¶é›†ç›‘æ§ç»“æœ
            db_summary = self.db_monitor.get_changes_summary()
            file_changes = self.file_monitor.changes_log
            
            results = {
                'database_changes': db_summary,
                'file_changes': file_changes,
                'monitoring_duration': time.time()
            }
            
            self.logger.info("ğŸ“Š ç›‘æ§ç»“æœå·²æ”¶é›†")
            return results
            
        except Exception as e:
            self.logger.error(f"åœæ­¢ç›‘æ§å¤±è´¥: {str(e)}")
            return {}
    
    def export_monitoring_results(self, results: Dict, output_file: str = None) -> str:
        """å¯¼å‡ºç›‘æ§ç»“æœåˆ°æ–‡ä»¶"""
        try:
            if not output_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = f"cursor_monitor_results_{timestamp}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ“„ ç›‘æ§ç»“æœå·²å¯¼å‡º: {output_file}")
            return output_file
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºç»“æœå¤±è´¥: {str(e)}")
            return ""
    
    def analyze_auth_changes(self, results: Dict) -> Dict:
        """åˆ†æè®¤è¯ç›¸å…³çš„å˜åŒ–"""
        try:
            db_changes = results.get('database_changes', {})
            key_stats = db_changes.get('key_statistics', {})
            
            # ç­›é€‰è®¤è¯ç›¸å…³çš„é”®
            # ğŸ”¥ ä¿®å¤ï¼šç§»é™¤cursor.å‰ç¼€å­—æ®µç›‘æ§ï¼Œè¿™äº›å­—æ®µä¼šå¯¼è‡´å†²çª
            auth_keys = [
                'cursorAuth/cachedEmail',
                'cursorAuth/accessToken', 
                'cursorAuth/refreshToken',
                'cursorAuth/userId',
                'cursorAuth/cachedSignUpType',
                # ä¸å†ç›‘æ§cursor.å‰ç¼€å­—æ®µï¼Œè¿™äº›ä¼šå¯¼è‡´Cursoræ£€æµ‹åˆ°å†²çª
            ]
            
            auth_changes = {}
            for key in auth_keys:
                if key in key_stats:
                    auth_changes[key] = key_stats[key]
            
            # åˆ†æå˜åŒ–æ¨¡å¼
            analysis = {
                'auth_field_changes': auth_changes,
                'total_auth_changes': sum(sum(stats.values()) for stats in auth_changes.values()),
                'change_pattern': self._analyze_change_pattern(results, auth_keys)
            }
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"åˆ†æè®¤è¯å˜åŒ–å¤±è´¥: {str(e)}")
            return {}
    
    def analyze_machine_id_changes(self, results: Dict) -> Dict:
        """åˆ†ææœºå™¨ç ç›¸å…³çš„å˜åŒ–"""
        try:
            db_changes = results.get('database_changes', {})
            key_stats = db_changes.get('key_statistics', {})
            
            # ç­›é€‰æœºå™¨ç ç›¸å…³çš„é”®
            machine_keys = [
                'telemetry.devDeviceId',
                'telemetry.macMachineId',
                'telemetry.machineId',
                'telemetry.sqmId',
                'storage.serviceMachineId'
            ]
            
            machine_changes = {}
            for key in machine_keys:
                if key in key_stats:
                    machine_changes[key] = key_stats[key]
            
            # åˆ†ææ–‡ä»¶å˜åŒ–
            file_changes = results.get('file_changes', [])
            machine_file_changes = [
                change for change in file_changes 
                if change['filename'] in ['storage.json', 'machineId']
            ]
            
            analysis = {
                'machine_field_changes': machine_changes,
                'machine_file_changes': machine_file_changes,
                'total_machine_changes': sum(sum(stats.values()) for stats in machine_changes.values()),
                'change_sequence': self._get_machine_change_sequence(results)
            }
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"åˆ†ææœºå™¨ç å˜åŒ–å¤±è´¥: {str(e)}")
            return {}
    
    def _analyze_change_pattern(self, results: Dict, target_keys: List[str]) -> List[Dict]:
        """åˆ†æå˜åŒ–æ¨¡å¼"""
        timeline = results.get('database_changes', {}).get('timeline', [])
        pattern = []
        
        for log_entry in timeline:
            timestamp = log_entry['timestamp']
            changes = log_entry['changes']
            
            relevant_changes = [
                change for change in changes 
                if change['key'] in target_keys
            ]
            
            if relevant_changes:
                pattern.append({
                    'timestamp': timestamp,
                    'changes': relevant_changes
                })
        
        return pattern
    
    def _get_machine_change_sequence(self, results: Dict) -> List[Dict]:
        """è·å–æœºå™¨ç å˜åŒ–åºåˆ—"""
        timeline = results.get('database_changes', {}).get('timeline', [])
        file_changes = results.get('file_changes', [])
        
        # åˆå¹¶æ•°æ®åº“å’Œæ–‡ä»¶å˜åŒ–
        all_changes = []
        
        # æ·»åŠ æ•°æ®åº“å˜åŒ–
        for log_entry in timeline:
            timestamp = log_entry['timestamp']
            for change in log_entry['changes']:
                if any(keyword in change['key'] for keyword in ['telemetry', 'machine', 'device']):
                    all_changes.append({
                        'timestamp': timestamp,
                        'source': 'database',
                        'change': change
                    })
        
        # æ·»åŠ æ–‡ä»¶å˜åŒ–
        for file_change in file_changes:
            if file_change['filename'] in ['storage.json', 'machineId']:
                all_changes.append({
                    'timestamp': file_change['timestamp'],
                    'source': 'file',
                    'change': file_change
                })
        
        # æŒ‰æ—¶é—´æ’åº
        all_changes.sort(key=lambda x: x['timestamp'])
        
        return all_changes


def create_monitoring_session(config) -> CursorOperationMonitor:
    """åˆ›å»ºç›‘æ§ä¼šè¯"""
    monitor = CursorOperationMonitor(config)
    return monitor


def read_binary_file_as_text(file_path: str, encoding_attempts: List[str] = None) -> Tuple[bool, str]:
    """
    å°è¯•ä»¥ä¸åŒç¼–ç è¯»å–å¯èƒ½çš„äºŒè¿›åˆ¶æ–‡ä»¶
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        encoding_attempts: å°è¯•çš„ç¼–ç åˆ—è¡¨
        
    Returns:
        Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, æ–‡ä»¶å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯)
    """
    if encoding_attempts is None:
        encoding_attempts = ['utf-8', 'gbk', 'latin-1', 'ascii']
    
    for encoding in encoding_attempts:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                content = f.read()
            return True, content
        except UnicodeDecodeError:
            continue
        except Exception as e:
            return False, f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"
    
    # å¦‚æœæ‰€æœ‰æ–‡æœ¬ç¼–ç éƒ½å¤±è´¥ï¼Œå°è¯•äºŒè¿›åˆ¶è¯»å–å¹¶è½¬æ¢ä¸ºåå…­è¿›åˆ¶
    try:
        with open(file_path, 'rb') as f:
            binary_content = f.read()
        
        # å¦‚æœæ–‡ä»¶å¾ˆå°ï¼Œå¯èƒ½æ˜¯æ–‡æœ¬æ–‡ä»¶
        if len(binary_content) < 1024:
            hex_content = binary_content.hex()
            return True, f"äºŒè¿›åˆ¶å†…å®¹(hex): {hex_content}"
        else:
            return True, f"äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå¤§å°: {len(binary_content)} å­—èŠ‚"
            
    except Exception as e:
        return False, f"è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶å¤±è´¥: {str(e)}"


if __name__ == "__main__":
    # æµ‹è¯•è¯»å–state.mdæ–‡ä»¶
    state_file = "state.md"
    if os.path.exists(state_file):
        success, content = read_binary_file_as_text(state_file)
        if success:
            print(f"æ–‡ä»¶å†…å®¹:\n{content}")
        else:
            print(f"è¯»å–å¤±è´¥: {content}")
    else:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {state_file}")
